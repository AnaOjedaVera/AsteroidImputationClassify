{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bc3d60-365e-4cd8-926c-582746e5f05d",
   "metadata": {},
   "source": [
    "# Imputation method of spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0183f6-26f7-406a-996d-b1d6f128faa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8524c7-2e32-4267-9668-045ac9eab58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import random\n",
    "csv_file_path = '02-Base.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df_spectra = df.iloc[:, 0:53]\n",
    "albedo_column = df.iloc[:, 53]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404a3c5-4b6d-4eaf-9a26-a829e8b39d8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final method - Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa8d07-08d1-4172-b67b-804351752a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import random\n",
    "\n",
    "# Set global font to DejaVu Serif and increase font sizes\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# ---------------------------\n",
    "# Load Data\n",
    "# ---------------------------\n",
    "csv_file_path = '02-Base.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Assume spectral data are in the first 53 columns.\n",
    "df_spectra = df.iloc[:, 0:53].copy()\n",
    "total_cols = df_spectra.shape[1]  # typically 53\n",
    "wavelengths = np.array([float(col) for col in df_spectra.columns])\n",
    "\n",
    "# ---------------------------\n",
    "# Load class labels from column \"class_asteroid_sf\".\n",
    "# ---------------------------\n",
    "if 'class_asteroid_sf' in df.columns:\n",
    "    classes = df['class_asteroid_sf']\n",
    "else:\n",
    "    raise ValueError(\"No 'class_asteroid_sf' column found in the CSV data.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Imputation Parameters\n",
    "# ---------------------------\n",
    "overlap_points = 21   # number of points used for overlapping region\n",
    "slope_weight = 1.0    # slope weight = 1 for all imputation\n",
    "\n",
    "# ---------------------------\n",
    "# Function to compute error metric for a candidate.\n",
    "# Uses:\n",
    "#   - MSE computed with average shift over the overlapping region.\n",
    "#   - Slope difference computed after aligning using the \"i point\":\n",
    "#       * For left-incomplete: use the first overlapping point.\n",
    "#       * For right-incomplete: use the last overlapping point.\n",
    "# ---------------------------\n",
    "def compute_similarity_aligned(target, candidate, indices, slope_weight, side=\"left\"):\n",
    "    shift_avg = np.mean(target[indices] - candidate[indices])\n",
    "    candidate_aligned_avg = candidate + shift_avg\n",
    "    mse = np.mean((target[indices] - candidate_aligned_avg[indices])**2)\n",
    "    \n",
    "    if side == \"left\":\n",
    "        shift_point = target[indices[0]] - candidate[indices[0]]\n",
    "    else:\n",
    "        shift_point = target[indices[-1]] - candidate[indices[-1]]\n",
    "    candidate_aligned = candidate + shift_point\n",
    "    if len(indices) > 1:\n",
    "        target_slopes = np.diff(target[indices])\n",
    "        candidate_slopes = np.diff(candidate_aligned[indices])\n",
    "        slope_diff = np.mean(np.abs(target_slopes - candidate_slopes))\n",
    "    else:\n",
    "        slope_diff = 0.0\n",
    "    total_error = mse + slope_weight * slope_diff\n",
    "    return total_error\n",
    "\n",
    "# ---------------------------\n",
    "# Process all spectra and perform imputation for incomplete ones.\n",
    "# We'll store the final imputed spectra in final_imputed_list.\n",
    "# ---------------------------\n",
    "final_imputed_list = [None] * len(df_spectra)\n",
    "\n",
    "# Export a single PDF with one page per imputed (incomplete) spectrum.\n",
    "pdf = PdfPages(\"all_imputedA.pdf\")\n",
    "\n",
    "for i in range(len(df_spectra)):\n",
    "    sample_orig = df_spectra.iloc[i].values.astype(float)\n",
    "    # Use original for candidate selection.\n",
    "    sample = sample_orig.copy()\n",
    "    # If spectrum is complete, leave it unchanged.\n",
    "    if not (np.isnan(sample[0]) or np.isnan(sample[-1])):\n",
    "        final_imputed_list[i] = sample\n",
    "        continue\n",
    "\n",
    "    final_imputed = sample_orig.copy()  # working copy for final imputation\n",
    "    processed_left = False\n",
    "    processed_right = False\n",
    "\n",
    "    # ---- Left-side imputation ----\n",
    "    if np.isnan(sample[0]):\n",
    "        processed_left = True\n",
    "        first_obs = np.where(~np.isnan(sample))[0][0]\n",
    "        left_missing_indices = np.arange(0, first_obs)\n",
    "        left_overlap_indices = np.arange(first_obs, min(first_obs + overlap_points, total_cols))\n",
    "        \n",
    "        # Find candidate spectra with complete data in left missing & overlapping regions,\n",
    "        # and from the same class as the target.\n",
    "        candidates_left = []\n",
    "        for j in range(len(df_spectra)):\n",
    "            if j == i:\n",
    "                continue\n",
    "            if classes[j] != classes[i]:\n",
    "                continue\n",
    "            cand = df_spectra.iloc[j].values.astype(float)\n",
    "            if np.all(~np.isnan(cand[left_overlap_indices])) and np.all(~np.isnan(cand[left_missing_indices])):\n",
    "                candidates_left.append((j, cand))\n",
    "        \n",
    "        # --- For targets of class \"R\", use all available candidates even if fewer than 10.\n",
    "        if classes[i] == \"R\":\n",
    "            if len(candidates_left) >= 1:\n",
    "                candidates_with_error_left = []\n",
    "                for cand_index, cand in candidates_left:\n",
    "                    err = compute_similarity_aligned(sample_orig, cand, left_overlap_indices, slope_weight, side=\"left\")\n",
    "                    candidates_with_error_left.append((cand_index, cand, err))\n",
    "                candidates_with_error_left.sort(key=lambda x: x[2])\n",
    "                best_candidates_left = candidates_with_error_left  # use all available candidates\n",
    "                imputed_left = []\n",
    "                errors_left = []\n",
    "                for cand_index, cand, err in best_candidates_left:\n",
    "                    errors_left.append(err)\n",
    "                    shift_point = sample_orig[left_overlap_indices[0]] - cand[left_overlap_indices[0]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    imputed_left.append(cand_aligned[left_missing_indices])\n",
    "                imputed_left = np.array(imputed_left)\n",
    "                errors_left = np.array(errors_left)\n",
    "                weights_left = 1.0 / (errors_left + 1e-6)\n",
    "                weighted_imputed_left = np.average(imputed_left, axis=0, weights=weights_left)\n",
    "                \n",
    "                # Smoothing: blend the first four missing points with extrapolated trend.\n",
    "                if len(left_overlap_indices) >= 2:\n",
    "                    x0 = wavelengths[left_overlap_indices[0]]\n",
    "                    x1 = wavelengths[left_overlap_indices[1]]\n",
    "                    y0 = sample_orig[left_overlap_indices[0]]\n",
    "                    y1 = sample_orig[left_overlap_indices[1]]\n",
    "                    slope_left = (y1 - y0) / (x1 - x0)\n",
    "                else:\n",
    "                    slope_left = 0\n",
    "                smoothed_left = weighted_imputed_left.copy()\n",
    "                for idx_missing, m in enumerate(left_missing_indices):\n",
    "                    d = first_obs - m  # distance from the boundary\n",
    "                    if d == 1:\n",
    "                        w = 0.5\n",
    "                    elif d == 2:\n",
    "                        w = 0.35\n",
    "                    elif d == 3:\n",
    "                        w = 0.25\n",
    "                    elif d == 4:\n",
    "                        w = 0.15\n",
    "                    elif d == 5:\n",
    "                        w = 0.1\n",
    "                    elif d == 6:\n",
    "                        w = 0.05\n",
    "                    elif d == 7:\n",
    "                        w = 0.0\n",
    "                    else:\n",
    "                        w = 0.0\n",
    "                    if w > 0:\n",
    "                        extrapolated_val = sample_orig[left_overlap_indices[0]] - slope_left * (x0 - wavelengths[m])\n",
    "                        smoothed_left[idx_missing] = w * extrapolated_val + (1 - w) * weighted_imputed_left[idx_missing]\n",
    "                weighted_imputed_left = smoothed_left\n",
    "                \n",
    "                final_imputed[left_missing_indices] = weighted_imputed_left\n",
    "                \n",
    "                # Plot left-side imputation.\n",
    "                fig, ax = plt.subplots(figsize=(10,6))\n",
    "                for cand_index, cand, err in best_candidates_left:\n",
    "                    shift_point = sample_orig[left_overlap_indices[0]] - cand[left_overlap_indices[0]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    ax.plot(wavelengths, cand_aligned, color='lightgray', linewidth=1, zorder=1)\n",
    "                ax.plot(wavelengths, sample_orig, 'ko-', label=\"Target (Observed)\", zorder=3)\n",
    "                ax.plot(wavelengths, final_imputed, 'b--', label=\"Final Imputed Spectrum\", zorder=4)\n",
    "                ax.scatter(wavelengths[left_missing_indices], final_imputed[left_missing_indices], color='red', \n",
    "                           label=\"Imputed Points\", zorder=5)\n",
    "                ax.axvspan(wavelengths[left_missing_indices[0]], wavelengths[left_missing_indices[-1]], \n",
    "                           color='red', alpha=0.2, label=\"Missing Region\", zorder=2)\n",
    "                ax.set_xlabel(\"Wavelength (µm)\")\n",
    "                ax.set_ylabel(\"ln(Reflectance)\")\n",
    "                ax.legend()\n",
    "                ax.text(0.5, -0.2, f\"Target {i}: Left Imputation\", transform=ax.transAxes, \n",
    "                        ha='center', va='center', fontsize=20)\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        else:\n",
    "            if len(candidates_left) < 10:\n",
    "                pass  # Skip left-imputation if not enough candidates.\n",
    "            else:\n",
    "                candidates_with_error_left = []\n",
    "                for cand_index, cand in candidates_left:\n",
    "                    err = compute_similarity_aligned(sample_orig, cand, left_overlap_indices, slope_weight, side=\"left\")\n",
    "                    candidates_with_error_left.append((cand_index, cand, err))\n",
    "                candidates_with_error_left.sort(key=lambda x: x[2])\n",
    "                best_candidates_left = candidates_with_error_left[:10]\n",
    "                \n",
    "                imputed_left = []\n",
    "                errors_left = []\n",
    "                for cand_index, cand, err in best_candidates_left:\n",
    "                    errors_left.append(err)\n",
    "                    shift_point = sample_orig[left_overlap_indices[0]] - cand[left_overlap_indices[0]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    imputed_left.append(cand_aligned[left_missing_indices])\n",
    "                imputed_left = np.array(imputed_left)\n",
    "                errors_left = np.array(errors_left)\n",
    "                weights_left = 1.0 / (errors_left + 1e-6)\n",
    "                weighted_imputed_left = np.average(imputed_left, axis=0, weights=weights_left)\n",
    "                \n",
    "                if len(left_overlap_indices) >= 2:\n",
    "                    x0 = wavelengths[left_overlap_indices[0]]\n",
    "                    x1 = wavelengths[left_overlap_indices[1]]\n",
    "                    y0 = sample_orig[left_overlap_indices[0]]\n",
    "                    y1 = sample_orig[left_overlap_indices[1]]\n",
    "                    slope_left = (y1 - y0) / (x1 - x0)\n",
    "                else:\n",
    "                    slope_left = 0\n",
    "                smoothed_left = weighted_imputed_left.copy()\n",
    "                for idx_missing, m in enumerate(left_missing_indices):\n",
    "                    d = first_obs - m\n",
    "                    if d == 1:\n",
    "                        w = 0.5\n",
    "                    elif d == 2:\n",
    "                        w = 0.35\n",
    "                    elif d == 3:\n",
    "                        w = 0.25\n",
    "                    elif d == 4:\n",
    "                        w = 0.15\n",
    "                    elif d == 5:\n",
    "                        w = 0.1\n",
    "                    elif d == 6:\n",
    "                        w = 0.05\n",
    "                    elif d == 7:\n",
    "                        w = 0.0\n",
    "                    else:\n",
    "                        w = 0.0\n",
    "                    if w > 0:\n",
    "                        extrapolated_val = sample_orig[left_overlap_indices[0]] - slope_left * (x0 - wavelengths[m])\n",
    "                        smoothed_left[idx_missing] = w * extrapolated_val + (1 - w) * weighted_imputed_left[idx_missing]\n",
    "                weighted_imputed_left = smoothed_left\n",
    "                \n",
    "                final_imputed[left_missing_indices] = weighted_imputed_left\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10,6))\n",
    "                for cand_index, cand, err in best_candidates_left:\n",
    "                    shift_point = sample_orig[left_overlap_indices[0]] - cand[left_overlap_indices[0]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    ax.plot(wavelengths, cand_aligned, color='lightgray', linewidth=1, zorder=1)\n",
    "                ax.plot(wavelengths, sample_orig, 'ko-', label=\"Target (Observed)\", zorder=3)\n",
    "                ax.plot(wavelengths, final_imputed, 'b--', label=\"Final Imputed Spectrum\", zorder=4)\n",
    "                ax.scatter(wavelengths[left_missing_indices], final_imputed[left_missing_indices], color='red', \n",
    "                           label=\"Imputed Points\", zorder=5)\n",
    "                ax.axvspan(wavelengths[left_missing_indices[0]], wavelengths[left_missing_indices[-1]], \n",
    "                           color='red', alpha=0.2, label=\"Missing Region\", zorder=2)\n",
    "                ax.set_xlabel(\"Wavelength (µm)\")\n",
    "                ax.set_ylabel(\"ln(Reflectance)\")\n",
    "                ax.legend()\n",
    "                ax.text(0.5, -0.2, f\"Target {i}: Left Imputation\", transform=ax.transAxes, \n",
    "                        ha='center', va='center', fontsize=20)\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "    # ---- Right-side imputation ----\n",
    "    if np.isnan(sample[-1]):\n",
    "        processed_right = True\n",
    "        last_obs = np.where(~np.isnan(sample))[0][-1]\n",
    "        right_missing_indices = np.arange(last_obs + 1, total_cols)\n",
    "        right_overlap_indices = np.arange(max(0, last_obs - overlap_points + 1), last_obs + 1)\n",
    "        \n",
    "        candidates_right = []\n",
    "        for j in range(len(df_spectra)):\n",
    "            if j == i:\n",
    "                continue\n",
    "            if classes[j] != classes[i]:\n",
    "                continue\n",
    "            cand = df_spectra.iloc[j].values.astype(float)\n",
    "            if np.all(~np.isnan(cand[right_overlap_indices])) and np.all(~np.isnan(cand[right_missing_indices])):\n",
    "                candidates_right.append((j, cand))\n",
    "                \n",
    "        if classes[i] == \"R\":\n",
    "            if len(candidates_right) >= 1:\n",
    "                candidates_with_error_right = []\n",
    "                for cand_index, cand in candidates_right:\n",
    "                    err = compute_similarity_aligned(sample_orig, cand, right_overlap_indices, slope_weight, side=\"right\")\n",
    "                    candidates_with_error_right.append((cand_index, cand, err))\n",
    "                candidates_with_error_right.sort(key=lambda x: x[2])\n",
    "                best_candidates_right = candidates_with_error_right  # use all available candidates\n",
    "                imputed_right = []\n",
    "                errors_right = []\n",
    "                for cand_index, cand, err in best_candidates_right:\n",
    "                    errors_right.append(err)\n",
    "                    shift_point = sample_orig[right_overlap_indices[-1]] - cand[right_overlap_indices[-1]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    imputed_right.append(cand_aligned[right_missing_indices])\n",
    "                imputed_right = np.array(imputed_right)\n",
    "                errors_right = np.array(errors_right)\n",
    "                weights_right = 1.0 / (errors_right + 1e-6)\n",
    "                weighted_imputed_right = np.average(imputed_right, axis=0, weights=weights_right)\n",
    "                \n",
    "                if len(right_overlap_indices) >= 2:\n",
    "                    x0 = wavelengths[right_overlap_indices[-2]]\n",
    "                    x1 = wavelengths[right_overlap_indices[-1]]\n",
    "                    y0 = sample_orig[right_overlap_indices[-2]]\n",
    "                    y1 = sample_orig[right_overlap_indices[-1]]\n",
    "                    slope_right = (y1 - y0) / (x1 - x0)\n",
    "                else:\n",
    "                    slope_right = 0\n",
    "                smoothed_right = weighted_imputed_right.copy()\n",
    "                for idx_missing, m in enumerate(right_missing_indices):\n",
    "                    d = m - last_obs  # distance from boundary\n",
    "                    if d == 1:\n",
    "                        w = 0.5\n",
    "                    elif d == 2:\n",
    "                        w = 0.35\n",
    "                    elif d == 3:\n",
    "                        w = 0.25\n",
    "                    elif d == 4:\n",
    "                        w = 0.15\n",
    "                    elif d == 5:\n",
    "                        w = 0.1\n",
    "                    elif d == 6:\n",
    "                        w = 0.05\n",
    "                    elif d == 7:\n",
    "                        w = 0.0\n",
    "                    else:\n",
    "                        w = 0.0\n",
    "                    if w > 0:\n",
    "                        extrapolated_val = sample_orig[right_overlap_indices[-1]] + slope_right * (wavelengths[m] - wavelengths[right_overlap_indices[-1]])\n",
    "                        smoothed_right[idx_missing] = w * extrapolated_val + (1 - w) * weighted_imputed_right[idx_missing]\n",
    "                weighted_imputed_right = smoothed_right\n",
    "                final_imputed[right_missing_indices] = weighted_imputed_right\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10,6))\n",
    "                for cand_index, cand, err in best_candidates_right:\n",
    "                    shift_point = sample_orig[right_overlap_indices[-1]] - cand[right_overlap_indices[-1]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    ax.plot(wavelengths, cand_aligned, color='lightgray', linewidth=1, zorder=1)\n",
    "                ax.plot(wavelengths, sample_orig, 'ko-', label=\"Target (Observed)\", zorder=3)\n",
    "                ax.plot(wavelengths, final_imputed, 'b--', label=\"Final Imputed Spectrum\", zorder=4)\n",
    "                ax.scatter(wavelengths[right_missing_indices], final_imputed[right_missing_indices], color='red', \n",
    "                           label=\"Imputed Points\", zorder=5)\n",
    "                ax.axvspan(wavelengths[right_missing_indices[0]], wavelengths[right_missing_indices[-1]], \n",
    "                           color='red', alpha=0.2, label=\"Missing Region\", zorder=2)\n",
    "                ax.set_xlabel(\"Wavelength (µm)\")\n",
    "                ax.set_ylabel(\"ln(Reflectance)\")\n",
    "                ax.legend()\n",
    "                ax.text(0.5, -0.2, f\"Target {i}: Right Imputation\", transform=ax.transAxes, \n",
    "                        ha='center', va='center', fontsize=20)\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                plt.close()\n",
    "        else:\n",
    "            if len(candidates_right) < 10:\n",
    "                pass\n",
    "            else:\n",
    "                candidates_with_error_right = []\n",
    "                for cand_index, cand in candidates_right:\n",
    "                    err = compute_similarity_aligned(sample_orig, cand, right_overlap_indices, slope_weight, side=\"right\")\n",
    "                    candidates_with_error_right.append((cand_index, cand, err))\n",
    "                candidates_with_error_right.sort(key=lambda x: x[2])\n",
    "                best_candidates_right = candidates_with_error_right[:10]\n",
    "                \n",
    "                imputed_right = []\n",
    "                errors_right = []\n",
    "                for cand_index, cand, err in best_candidates_right:\n",
    "                    errors_right.append(err)\n",
    "                    shift_point = sample_orig[right_overlap_indices[-1]] - cand[right_overlap_indices[-1]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    imputed_right.append(cand_aligned[right_missing_indices])\n",
    "                imputed_right = np.array(imputed_right)\n",
    "                errors_right = np.array(errors_right)\n",
    "                weights_right = 1.0 / (errors_right + 1e-6)\n",
    "                weighted_imputed_right = np.average(imputed_right, axis=0, weights=weights_right)\n",
    "                \n",
    "                if len(right_overlap_indices) >= 2:\n",
    "                    x0 = wavelengths[right_overlap_indices[-2]]\n",
    "                    x1 = wavelengths[right_overlap_indices[-1]]\n",
    "                    y0 = sample_orig[right_overlap_indices[-2]]\n",
    "                    y1 = sample_orig[right_overlap_indices[-1]]\n",
    "                    slope_right = (y1 - y0) / (x1 - x0)\n",
    "                else:\n",
    "                    slope_right = 0\n",
    "                smoothed_right = weighted_imputed_right.copy()\n",
    "                for idx_missing, m in enumerate(right_missing_indices):\n",
    "                    d = m - last_obs\n",
    "                    if d == 1:\n",
    "                        w = 0.5\n",
    "                    elif d == 2:\n",
    "                        w = 0.35\n",
    "                    elif d == 3:\n",
    "                        w = 0.25\n",
    "                    elif d == 4:\n",
    "                        w = 0.15\n",
    "                    elif d == 5:\n",
    "                        w = 0.1\n",
    "                    elif d == 6:\n",
    "                        w = 0.05\n",
    "                    elif d == 7:\n",
    "                        w = 0.0\n",
    "                    else:\n",
    "                        w = 0.0\n",
    "                    if w > 0:\n",
    "                        extrapolated_val = sample_orig[right_overlap_indices[-1]] + slope_right * (wavelengths[m] - wavelengths[right_overlap_indices[-1]])\n",
    "                        smoothed_right[idx_missing] = w * extrapolated_val + (1 - w) * weighted_imputed_right[idx_missing]\n",
    "                weighted_imputed_right = smoothed_right\n",
    "                final_imputed[right_missing_indices] = weighted_imputed_right\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10,6))\n",
    "                for cand_index, cand, err in best_candidates_right:\n",
    "                    shift_point = sample_orig[right_overlap_indices[-1]] - cand[right_overlap_indices[-1]]\n",
    "                    cand_aligned = cand + shift_point\n",
    "                    ax.plot(wavelengths, cand_aligned, color='lightgray', linewidth=1, zorder=1)\n",
    "                ax.plot(wavelengths, sample_orig, 'ko-', label=\"Target (Observed)\", zorder=3)\n",
    "                ax.plot(wavelengths, final_imputed, 'b--', label=\"Final Imputed Spectrum\", zorder=4)\n",
    "                ax.scatter(wavelengths[right_missing_indices], final_imputed[right_missing_indices], color='red', \n",
    "                           label=\"Imputed Points\", zorder=5)\n",
    "                ax.axvspan(wavelengths[right_missing_indices[0]], wavelengths[right_missing_indices[-1]], \n",
    "                           color='red', alpha=0.2, label=\"Missing Region\", zorder=2)\n",
    "                ax.set_xlabel(\"Wavelength (µm)\")\n",
    "                ax.set_ylabel(\"ln(Reflectance)\")\n",
    "                ax.legend()\n",
    "                ax.text(0.5, -0.2, f\"Target {i}: Right Imputation\", transform=ax.transAxes, \n",
    "                        ha='center', va='center', fontsize=20)\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                plt.close()\n",
    "    \n",
    "    final_imputed_list[i] = final_imputed\n",
    "\n",
    "pdf.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Export final imputed spectra to CSV\n",
    "# ---------------------------\n",
    "df_imputed = pd.DataFrame(final_imputed_list, columns=df_spectra.columns, index=df_spectra.index)\n",
    "df_imputed.to_csv(\"03-Base-imputedA.csv\", index=False)\n",
    "\n",
    "print(\"PDF of all imputed spectra exported to 'all_imputedA.pdf'.\")\n",
    "print(\"CSV of final imputed spectra exported to '03-Base-imputedA.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c10193-5960-4436-ab21-820ad2ae71c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final method - Albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed38a51-a8ba-4f57-9f27-aded4b6f07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "csv_file_path = '02-Base.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Identify missing pV values\n",
    "missing_pV_data = df[df['pV'].isna()]\n",
    "names_missing_pV = missing_pV_data['name'].unique()\n",
    "\n",
    "# Fill missing values with mean pV of the same name\n",
    "for name in names_missing_pV:\n",
    "#    print(f\"Name: {name} (Missing pV data)\")\n",
    "    all_entries_for_name = df[df['name'] == name]\n",
    "    available_pV_data = all_entries_for_name[all_entries_for_name['pV'].notna()]\n",
    "    \n",
    "    if not available_pV_data.empty:\n",
    "        mean_pV = available_pV_data['pV'].mean()\n",
    "        df.loc[(df['name'] == name) & (df['pV'].isna()), 'pV'] = mean_pV\n",
    "#        print(f\"Filled missing 'pV' for {name} with mean value: {mean_pV:.4f}\")\n",
    "#    else:\n",
    "#        print(\"No entries with available pV data.\")\n",
    "#    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Save the updated DataFrame with the same original columns\n",
    "df.to_csv('03-Base-imputed3.csv', index=False)\n",
    "print(\"Missing 'pV' values have been filled with mean values, and the updated CSV file '03-Base-imputed3.csv' has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4336ac-b229-4a87-875a-dd81d5fdb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the updated CSV and count remaining missing pV values\n",
    "updated_df = pd.read_csv('03-Base-imputed3.csv')\n",
    "remaining_missing_pV = updated_df['pV'].isna().sum()\n",
    "print(f\"Total remaining missing 'pV' values: {remaining_missing_pV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f2723-bd4d-46ab-9986-8023fa59eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Set global font to DejaVu Serif and increase font sizes\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Load CSV\n",
    "csv_file_path = '03-Base-imputed3.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Identify remaining missing pV values\n",
    "remaining_missing_pV_data = df[df['pV'].isna()]\n",
    "remaining_missing_pV_count = remaining_missing_pV_data.shape[0]\n",
    "print(f\"Total remaining missing 'pV' values: {remaining_missing_pV_count}\")\n",
    "\n",
    "# Fill missing pV values based on class\n",
    "pdf_filename = 'pV_class_analysis.pdf'\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    for classi in df['class_asteroid_sf'].unique():\n",
    "        class_samples = df[df['class_asteroid_sf'] == classi]\n",
    "        pV_values_class = class_samples['pV'].dropna()\n",
    "        \n",
    "        if not pV_values_class.empty:\n",
    "            Q1 = pV_values_class.quantile(0.25)\n",
    "            Q2 = pV_values_class.quantile(0.50)  # Median (Q2)\n",
    "            Q3 = pV_values_class.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            is_outlier = (pV_values_class < lower_bound) | (pV_values_class > upper_bound)\n",
    "            weights = np.where(is_outlier, 0.1, 1.0)\n",
    "            weighted_mean_pV_class = np.average(pV_values_class, weights=weights)\n",
    "            \n",
    "            missing_pV_indices = (df['class_asteroid_sf'] == classi) & (df['pV'].isna())\n",
    "            df.loc[missing_pV_indices, 'pV'] = weighted_mean_pV_class\n",
    "            \n",
    "            # Generate plot\n",
    "            plt.figure(figsize=(10, 4))  # Decreased height to shrink the plot on y-axis\n",
    "            box = plt.boxplot(pV_values_class, vert=False, patch_artist=True, showfliers=True, \n",
    "                              flierprops=dict(marker='o', color='red', alpha=0.5), widths=0.3)  # Further shrinking boxplot height\n",
    "            \n",
    "            # Increase thickness of Q2 (median) line\n",
    "            for median in box['medians']:\n",
    "                median.set(linewidth=3.5, color='orange')\n",
    "            \n",
    "            plt.axvline(x=lower_bound, color='blue', linestyle='--', label=f'Lower bound (Outlier): {lower_bound:.2f}', linewidth=3)\n",
    "            plt.axvline(x=upper_bound, color='blue', linestyle='--', label=f'Upper bound (Outlier): {upper_bound:.2f}', linewidth=3)\n",
    "            plt.title(f'Box plot of \"pV\" for class {classi} with outliers')\n",
    "            plt.xlabel('log10 pV')\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.tight_layout(rect=[0, 0.02, 1, 1])  # Adjust layout to move content up\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "print(f\"The PDF file with results and plots has been saved as '{pdf_filename}'.\")\n",
    "\n",
    "# Save the updated DataFrame with filled pV values\n",
    "df.to_csv('03-Base-imputed223.csv', index=False)\n",
    "print(\"Update complete. Missing 'pV' values have been imputed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4819f-c8d0-47e2-8114-c17185e89565",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final database (concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc4195-54f4-46e5-9393-dbc38b8491a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('03-Base-imputedA.csv')  # Original spectra dataset\n",
    "df2 = pd.read_csv('03-Base-imputed223.csv')  # Contains extra columns\n",
    "extra_columns = ['pV', 'name', 'counts', 'class_bdm', 'class_asteroid_sf']\n",
    "df2_extra = df2[extra_columns]\n",
    "# Ensure both datasets have the same length before concatenation\n",
    "if len(df1) == len(df2_extra):\n",
    "    merged_df = pd.concat([df1, df2_extra], axis=1)  # Concatenate columns\n",
    "    merged_df.to_csv('05-Base.csv', index=False)\n",
    "    print(\"Merging complete. The new file '05-Base.csv' has been created.\")\n",
    "else:\n",
    "    print(\"Error: The two datasets have different numbers of rows. Check for missing or extra data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
